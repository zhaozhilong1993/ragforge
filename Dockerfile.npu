# base stage
FROM ubuntu:22.04 AS base
#FROM swr.cn-central-221.ovaijisuan.com/mindformers/mindformers1.2_mindspore2.3:20240722 AS base
USER root
SHELL ["/bin/bash", "-c"]

ARG NEED_MIRROR=1
ARG LIGHTEN=0
ENV LIGHTEN=${LIGHTEN}

WORKDIR /ragflow

# Copy models downloaded via download_deps.py
RUN mkdir -p /ragflow/rag/res/deepdoc /root/.ragflow
RUN --mount=type=bind,from=infiniflow/ragflow_deps:latest,source=/huggingface.co,target=/huggingface.co \
    cp /huggingface.co/InfiniFlow/huqie/huqie.txt.trie /ragflow/rag/res/ && \
    tar --exclude='.*' -cf - \
        /huggingface.co/InfiniFlow/text_concat_xgb_v1.0 \
        /huggingface.co/InfiniFlow/deepdoc \
        | tar -xf - --strip-components=3 -C /ragflow/rag/res/deepdoc 
RUN --mount=type=bind,from=infiniflow/ragflow_deps:latest,source=/huggingface.co,target=/huggingface.co \
    if [ "$LIGHTEN" != "1" ]; then \
        (tar -cf - \
            /huggingface.co/BAAI/bge-large-zh-v1.5 \
            /huggingface.co/maidalun1020/bce-embedding-base_v1 \
            | tar -xf - --strip-components=2 -C /root/.ragflow) \
    fi

# https://github.com/chrismattmann/tika-python
# This is the only way to run python-tika without internet access. Without this set, the default is to check the tika version and pull latest every time from Apache.
RUN --mount=type=bind,from=infiniflow/ragflow_deps:latest,source=/,target=/deps \
    cp -r /deps/nltk_data /root/ && \
    cp /deps/tika-server-standard-3.0.0.jar /deps/tika-server-standard-3.0.0.jar.md5 /ragflow/ && \
    cp /deps/cl100k_base.tiktoken /ragflow/9b5ad71b2ce5302211f9c61530b329a4922fc6a4

ENV TIKA_SERVER_JAR="file:///ragflow/tika-server-standard-3.0.0.jar"
ENV DEBIAN_FRONTEND=noninteractive

# Setup apt
# Python package and implicit dependencies:
# opencv-python: libglib2.0-0 libglx-mesa0 libgl1
# aspose-slides: pkg-config libicu-dev libgdiplus         libssl1.1_1.1.1f-1ubuntu2_amd64.deb
# python-pptx:   default-jdk                              tika-server-standard-3.0.0.jar
# selenium:      libatk-bridge2.0-0                       chrome-linux64-121-0-6167-85
# Building C extensions: libpython3-dev libgtk-4-1 libnss3 xdg-utils libgbm-dev
RUN --mount=type=cache,id=ragflow_apt,target=/var/cache/apt,sharing=locked \
    if [ "$NEED_MIRROR" == "1" ]; then \
        sed -i 's|http://ports.ubuntu.com|http://mirrors.tuna.tsinghua.edu.cn|g' /etc/apt/sources.list; \
        sed -i 's|http://archive.ubuntu.com|http://mirrors.tuna.tsinghua.edu.cn|g' /etc/apt/sources.list; \
    fi; \
    rm -f /etc/apt/apt.conf.d/docker-clean && \
    echo 'Binary::apt::APT::Keep-Downloaded-Packages "true";' > /etc/apt/apt.conf.d/keep-cache && \
    chmod 1777 /tmp && \
    apt update && \
    apt --no-install-recommends install -y ca-certificates && \
    apt update && \
    apt install -y libglib2.0-0 libglx-mesa0 libgl1 && \
    apt install -y pkg-config libicu-dev libgdiplus && \
    apt install -y default-jdk && \
    apt install -y libatk-bridge2.0-0 && \
    apt install -y libpython3-dev libgtk-4-1 libnss3 xdg-utils libgbm-dev && \
    apt install -y libjemalloc-dev && \
    apt install -y libreoffice && \
    apt install -y python3-pip pipx nginx unzip curl wget git vim less

RUN if [ "$NEED_MIRROR" == "1" ]; then \
        pip3 config set global.index-url https://mirrors.aliyun.com/pypi/simple && \
        pip3 config set global.trusted-host mirrors.aliyun.com; \
        mkdir -p /etc/uv && \
        echo "[[index]]" > /etc/uv/uv.toml && \
        echo 'url = "https://mirrors.aliyun.com/pypi/simple"' >> /etc/uv/uv.toml && \
        echo "default = true" >> /etc/uv/uv.toml; \
    fi; \
    pipx install uv -i https://mirrors.aliyun.com/pypi/simple

ENV PYTHONDONTWRITEBYTECODE=1 DOTNET_SYSTEM_GLOBALIZATION_INVARIANT=1
ENV PATH=/root/.local/bin:$PATH

# nodejs 12.22 on Ubuntu 22.04 is too old
RUN --mount=type=cache,id=ragflow_apt,target=/var/cache/apt,sharing=locked \
    curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt purge -y nodejs npm cargo && \
    apt autoremove -y && \
    apt update && \
    apt install -y nodejs

#RUN export https_proxy=http://81.70.135.187:8118
#RUN export http_proxy=http://81.70.135.187:8118
# A modern version of cargo is needed for the latest version of the Rust compiler.
RUN apt update && apt install -y curl build-essential \
    && if [ "$NEED_MIRROR" == "1" ]; then \
         # Use TUNA mirrors for rustup/rust dist files
         export RUSTUP_DIST_SERVER="https://mirrors.tuna.tsinghua.edu.cn/rustup"; \
         export RUSTUP_UPDATE_ROOT="https://mirrors.tuna.tsinghua.edu.cn/rustup/rustup"; \
         echo "Using TUNA mirrors for Rustup."; \
       fi; \
    # Force curl to use HTTP/1.1
    curl --proto '=https' -x http://81.70.135.187:8118 --tlsv1.2 --http1.1 -sSf https://sh.rustup.rs | bash -s -- -y --profile minimal \
    && echo 'export PATH="/root/.cargo/bin:${PATH}"' >> /root/.bashrc

ENV PATH="/root/.cargo/bin:${PATH}"

RUN cargo --version && rustc --version

# Add msssql ODBC driver
# macOS ARM64 environment, install msodbcsql18.
# general x86_64 environment, install msodbcsql17.
RUN --mount=type=cache,id=ragflow_apt,target=/var/cache/apt,sharing=locked \
    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
    curl https://packages.microsoft.com/config/ubuntu/22.04/prod.list > /etc/apt/sources.list.d/mssql-release.list && \
    apt update && \
    arch="$(uname -m)"; \
    if [ "$arch" = "arm64" ] || [ "$arch" = "aarch64" ]; then \
        # ARM64 (macOS/Apple Silicon or Linux aarch64)
        ACCEPT_EULA=Y apt install -y unixodbc-dev msodbcsql18; \
    else \
        # x86_64 or others
        ACCEPT_EULA=Y apt install -y unixodbc-dev msodbcsql17; \
    fi || \
    { echo "Failed to install ODBC driver"; exit 1; }



# Add dependencies of selenium
RUN --mount=type=bind,from=infiniflow/ragflow_deps:latest,source=/chrome-linux64.zip,target=/chrome-linux64.zip \
    unzip /chrome-linux64.zip && \
    mv chrome-linux64 /opt/chrome && \
    ln -s /opt/chrome/chrome /usr/local/bin/
RUN --mount=type=bind,from=infiniflow/ragflow_deps:latest,source=/chromedriver-linux64.zip,target=/chromedriver-linux64.zip \
    unzip -j /chromedriver-linux64.zip chromedriver-linux64/chromedriver && \
    mv chromedriver /usr/local/bin/ && \
    rm -f /usr/bin/google-chrome

# https://forum.aspose.com/t/aspose-slides-for-net-no-usable-version-of-libssl-found-with-linux-server/271344/13
# aspose-slides on linux/arm64 is unavailable
RUN --mount=type=bind,from=infiniflow/ragflow_deps:latest,source=/,target=/deps \
    if [ "$(uname -m)" = "x86_64" ]; then \
        dpkg -i /deps/libssl1.1_1.1.1f-1ubuntu2_amd64.deb; \
    elif [ "$(uname -m)" = "aarch64" ]; then \
        dpkg -i /deps/libssl1.1_1.1.1f-1ubuntu2_arm64.deb; \
    fi

# builder stage
FROM base AS builder
USER root

WORKDIR /ragflow

# install dependencies from uv.lock file
COPY pyproject.toml uv.lock ./

# https://github.com/astral-sh/uv/issues/10462
# uv records index url into uv.lock but doesn't failover among multiple indexes
RUN --mount=type=cache,id=ragflow_uv,target=/root/.cache/uv,sharing=locked \
    if [ "$NEED_MIRROR" == "1" ]; then \
        sed -i 's|pypi.org|mirrors.aliyun.com/pypi|g' uv.lock; \
    else \
        sed -i 's|mirrors.aliyun.com/pypi|pypi.org|g' uv.lock; \
    fi; \
    if [ "$LIGHTEN" == "1" ]; then \
        uv sync --python 3.10 --frozen; \
    else \
        uv sync --python 3.10 --frozen --all-extras; \
    fi

COPY web web
COPY docs docs
RUN --mount=type=cache,id=ragflow_npm,target=/root/.npm,sharing=locked \
    cd web && npm install && npm run build

COPY .git /ragflow/.git

RUN version_info=$(git describe --tags --match=v* --first-parent --always); \
    if [ "$LIGHTEN" == "1" ]; then \
        version_info="$version_info slim"; \
    else \
        version_info="$version_info full"; \
    fi; \
    echo "RAGFlow version: $version_info"; \
    echo $version_info > /ragflow/VERSION


# production stage
FROM base AS production
USER root

WORKDIR /ragflow

# Copy Python environment and packages
ENV VIRTUAL_ENV=/ragflow/.venv
COPY --from=builder ${VIRTUAL_ENV} ${VIRTUAL_ENV}
ENV PATH="${VIRTUAL_ENV}/bin:${PATH}"

ENV PYTHONPATH=/ragflow/

COPY docker docker
COPY web web
COPY api api
COPY conf conf
COPY deepdoc deepdoc
COPY rag rag
COPY agent agent
COPY graphrag graphrag
COPY agentic_reasoning agentic_reasoning
COPY pyproject.toml uv.lock ./
COPY mcp mcp

COPY docker/service_conf.yaml.template ./conf/service_conf.yaml.template
COPY docker/entrypoint.sh ./
RUN chmod +x ./entrypoint*.sh
COPY docker/entrypoint_npu.sh ./
RUN chmod +x ./entrypoint_npu.sh

# Copy compiled web pages
COPY --from=builder /ragflow/web/dist /ragflow/web/dist

COPY --from=builder /ragflow/VERSION /ragflow/VERSION



# MinerU 环境
RUN export http_proxy=
RUN export https_proxy=
RUN wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/magic-pdf.template.json
RUN cp magic-pdf.template.json /root/magic-pdf.json
#RUN wget https://dl.min.io/client/mc/release/linux-amd64/mc -O /usr/bin/mc
COPY ./mc /usr/bin/.
RUN chmod +x  /usr/bin/mc
RUN pip3 install torch==2.6.0
RUN pip3 install torchvision==0.21.0 -i https://mirrors.aliyun.com/pypi/simple
RUN pip3 install numpy==1.26.4 -i https://mirrors.aliyun.com/pypi/simple
RUN pip3 install magic-pdf[full]==1.3.10 -i https://mirrors.aliyun.com/pypi/simple
RUN pip3 install modelscope -i https://mirrors.aliyun.com/pypi/simple
RUN pip3 install frontend -i https://mirrors.aliyun.com/pypi/simple
RUN wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/scripts/download_models.py -O download_models.py
RUN sed -i '1i sys.path.append("/usr/local/lib/python3.10/dist-packages")' download_models.py
#RUN sed -i '1i sys.path.append("/usr/local/python3.10/lib/python3.10/site-packages")' download_models.py
RUN sed -i '1i import sys' download_models.py
RUN python3 download_models.py
RUN apt install fonts-wqy-zenhei fonts-wqy-microhei  libreoffice-l10n-zh-cn -y



# 达梦数据库 环境
# 安装达梦数据库ODBC驱动依赖
WORKDIR /ragflow

RUN apt-get update && \
    apt-get install -y unixodbc unixodbc-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# 添加组和用户
#RUN groupadd dinstall && \
#    useradd -g dinstall -m dmdba && \
#    echo "dmdba:123456" | chpasswd

#RUN groupadd root && \
RUN useradd -g root -m dmdba && \
    echo "dmdba:123456" | chpasswd

# 在这里需要将达梦数据库驱动放入容器
# 注意：需要提前下载达梦数据库驱动包
RUN mkdir -p /opt/dm8
COPY drivers/dm/unixODBC-2.3.12.tar.gz /tmp/
RUN tar -zxvf /tmp/unixODBC-2.3.12.tar.gz -C /opt/dm8

# 创建驱动目录并添加空的驱动文件
RUN mkdir -p /opt/dm8/dm8_odbc_driver_linux_64 && \
    touch /opt/dm8/dm8_odbc_driver_linux_64/libdodbc.so && \
    chmod +x /opt/dm8/dm8_odbc_driver_linux_64/libdodbc.so

ADD docker/etc /etc
ADD docker/dm8 /opt/dm8
COPY drivers/linux-odbc/libdodbc.so /opt/dm8/dm8_odbc_driver_linux_64/
COPY drivers/linux-odbc/libdmdpi.so /opt/dm8/dm8_odbc_driver_linux_64/
COPY drivers/linux-odbc/libdmfldr.so /opt/dm8/dm8_odbc_driver_linux_64/
RUN chmod +x /opt/dm8/dm8_odbc_driver_linux_64/*.so

# 配置达梦数据库ODBC驱动 - 确保与代码中使用的驱动名称一致
RUN echo -e "[ODBC Data Sources]\nDM ODBC DRIVER = DM ODBC DRIVER\n[DM ODBC DRIVER]\nDriver = /opt/dm8/dm8_odbc_driver_linux_64/libdodbc.so\nSetup = /opt/dm8/dm8_odbc_driver_linux_64/libdodbc.so" > /etc/odbcinst.ini && \
    echo -e "[ODBC Data Sources]\nDM = DM ODBC DRIVER\n[DM]\nDriver = DM ODBC DRIVER\nServer = 118.193.126.254\nPort = 5236" > /etc/odbc.ini


# 设置环境变量
ENV ODBCINI=/etc/odbc.ini
ENV ODBCSYSINI=/etc
# 设置默认数据库类型为达梦
ENV DB_TYPE=dm

# 安装 Python 依赖
RUN pip config set global.index-url https://mirrors.aliyun.com/pypi/simple && \
    pip install --no-cache-dir pyodbc opensearch-py==2.8.0 -v && \
    pip list | grep opensearch

# 创建自定义的 opensearchpy 模块
RUN mkdir -p /usr/local/lib/python3.10/dist-packages/opensearchpy && \
    echo "# Import from opensearch_py package\ntry:\n    import sys\n    import os\n    # Try to find the opensearch_py package\n    paths = [p for p in sys.path if os.path.exists(os.path.join(p, 'opensearch_py'))]\n    if paths:\n        sys.path.insert(0, os.path.join(paths[0], 'opensearch_py'))\n    from opensearch_py import OpenSearch, NotFoundError, UpdateByQuery, Q, Search, Index, ConnectionTimeout\nexcept ImportError:\n    # If still cannot import, try another approach\n    from opensearch_py.opensearchpy import OpenSearch, NotFoundError, UpdateByQuery, Q, Search, Index, ConnectionTimeout\n\n# Export the names to make them available when importing this module\n__all__ = ['OpenSearch', 'NotFoundError', 'UpdateByQuery', 'Q', 'Search', 'Index', 'ConnectionTimeout']" > /usr/local/lib/python3.10/dist-packages/opensearchpy/__init__.py && \
    touch /usr/local/lib/python3.10/dist-packages/opensearchpy/__pycache__

# 创建软链接目录，确保能找到opensearchpy
RUN mkdir -p /ragflow/opensearchpy && \
    echo "from opensearchpy import *" > /ragflow/opensearchpy/__init__.py && \
    echo "/ragflow" > /usr/local/lib/python3.10/dist-packages/opensearchpy.pth



ENTRYPOINT ["./entrypoint.sh"]
#ENTRYPOINT ["./entrypoint_npu.sh"]
